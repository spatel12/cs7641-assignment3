{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.cluster import KMeans\n",
    "from yellowbrick.cluster import SilhouetteVisualizer\n",
    "from yellowbrick.cluster import InterclusterDistance\n",
    "from yellowbrick.cluster import KElbowVisualizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import time\n",
    "from scipy import linalg\n",
    "import matplotlib as mpl\n",
    "import itertools\n",
    "\n",
    "from sklearn.metrics import v_measure_score, homogeneity_score, adjusted_mutual_info_score\n",
    "\n",
    "\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.utils import check_random_state\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import (GridSearchCV, train_test_split, validation_curve)   \n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import preprocessing\n",
    "from yellowbrick.model_selection import LearningCurve, ValidationCurve\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import time\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(ds):\n",
    "    df = pd.read_csv(\"data/\" + ds)\n",
    "    X, y = df.iloc[:, :-1], df.iloc[:, -1]\n",
    "    X, y = X.to_numpy(), y.to_numpy()\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train time: 0.040306806564331055\n",
      "Query time: 0.0012507438659667969\n",
      "Cross validation score: 0.9187747035573122\n",
      "Train time: 1.4266328811645508\n",
      "Query time: 0.0009500980377197266\n",
      "Test Accuracy: 0.9385964912280702\n"
     ]
    }
   ],
   "source": [
    "# KMeans = 2\n",
    "X, y = load_data('wdbc-modified.data')\n",
    "pca = PCA(n_components= 2).fit(X)\n",
    "X_pca = pca.transform(X)\n",
    "start = time.time()\n",
    "kmeans=KMeans(2).fit(X_pca)\n",
    "train_time = time.time() - start\n",
    "print(\"Train time: \" + str(train_time))\n",
    "\n",
    "start = time.time()\n",
    "kmeans.predict(X_pca)\n",
    "query_time = time.time() - start\n",
    "print(\"Query time: \" + str(query_time))\n",
    "y = kmeans.predict(X_pca)\n",
    "\n",
    "result = pd.concat([pd.DataFrame(X_pca), pd.DataFrame(y)], axis=1, sort=False)\n",
    "result.columns = [0, 1, 2]\n",
    "\n",
    "X, y = load_data('wdbc-modified.data')\n",
    "\n",
    "clf = MLPClassifier(max_iter= 5000, hidden_layer_sizes=(5,2), activation='logistic', verbose=False, learning_rate_init=0.001)\n",
    "X_train, X_test, y_train, y_test = train_test_split(result, y, test_size=0.2)\n",
    "\n",
    "cv_score = cross_val_score(clf, X_train, y_train, cv=20).mean()\n",
    "print(\"Cross validation score: \" + str(cv_score))\n",
    "\n",
    "start = time.time()\n",
    "clf.fit(X_train, y_train)\n",
    "train_time = time.time() - start\n",
    "print(\"Train time: \" + str(train_time))\n",
    "\n",
    "start = time.time()\n",
    "y_pred = clf.predict(X_test)\n",
    "query_time = time.time() - start\n",
    "print(\"Query time: \" + str(query_time))\n",
    "\n",
    "score = accuracy_score(y_test, y_pred)\n",
    "print(\"Test Accuracy: \" + str(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train time: 0.014967203140258789\n",
      "Query time: 0.005136251449584961\n",
      "Cross validation score: 0.9160079051383399\n",
      "Train time: 1.0170092582702637\n",
      "Query time: 0.0013041496276855469\n",
      "Test Accuracy: 0.9210526315789473\n"
     ]
    }
   ],
   "source": [
    "# EM = 2\n",
    "X, y = load_data('wdbc-modified.data')\n",
    "pca = PCA(n_components= 2).fit(X)\n",
    "X_pca = pca.transform(X)\n",
    "start = time.time()\n",
    "kmeans=GaussianMixture(2).fit(X_pca)\n",
    "train_time = time.time() - start\n",
    "print(\"Train time: \" + str(train_time))\n",
    "\n",
    "start = time.time()\n",
    "kmeans.predict(X_pca)\n",
    "query_time = time.time() - start\n",
    "print(\"Query time: \" + str(query_time))\n",
    "y = kmeans.predict(X_pca)\n",
    "\n",
    "result = pd.concat([pd.DataFrame(X_pca), pd.DataFrame(y)], axis=1, sort=False)\n",
    "result.columns = [0, 1, 2]\n",
    "\n",
    "X, y = load_data('wdbc-modified.data')\n",
    "\n",
    "clf = MLPClassifier(max_iter= 5000, hidden_layer_sizes=(5,2), activation='logistic', verbose=False, learning_rate_init=0.001)\n",
    "X_train, X_test, y_train, y_test = train_test_split(result, y, test_size=0.2)\n",
    "\n",
    "cv_score = cross_val_score(clf, X_train, y_train, cv=20).mean()\n",
    "print(\"Cross validation score: \" + str(cv_score))\n",
    "\n",
    "start = time.time()\n",
    "clf.fit(X_train, y_train)\n",
    "train_time = time.time() - start\n",
    "print(\"Train time: \" + str(train_time))\n",
    "\n",
    "start = time.time()\n",
    "y_pred = clf.predict(X_test)\n",
    "query_time = time.time() - start\n",
    "print(\"Query time: \" + str(query_time))\n",
    "\n",
    "score = accuracy_score(y_test, y_pred)\n",
    "print(\"Test Accuracy: \" + str(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.46479332792160793\n",
      "0.46400471284520906\n",
      "0.42229071246999117\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# KMeans = 2\n",
    "X, y = load_data('wdbc-modified.data')\n",
    "pca = PCA(n_components= 2).fit(X)\n",
    "X_pca = pca.transform(X)\n",
    "start = time.time()\n",
    "kmeans=KMeans(2).fit(X_pca)\n",
    "labels = kmeans.predict(X_pca)\n",
    "\n",
    "print(v_measure_score(y, labels))\n",
    "print(adjusted_mutual_info_score(y, labels))\n",
    "print(homogeneity_score(y, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6470261554158523\n",
      "0.646544762580409\n",
      "0.6343604044495395\n"
     ]
    }
   ],
   "source": [
    "# Gaussian = 2\n",
    "X, y = load_data('wdbc-modified.data')\n",
    "pca = PCA(n_components= 2).fit(X)\n",
    "X_pca = pca.transform(X)\n",
    "start = time.time()\n",
    "kmeans=GaussianMixture(2).fit(X_pca)\n",
    "labels = kmeans.predict(X_pca)\n",
    "\n",
    "print(v_measure_score(y, labels))\n",
    "print(adjusted_mutual_info_score(y, labels))\n",
    "print(homogeneity_score(y, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
